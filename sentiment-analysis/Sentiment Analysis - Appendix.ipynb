{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "import time\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw data\n",
    "all_china = pd.read_csv('Desktop/w266-final-project/all_china_full_nort.csv')\n",
    "pro_china = pd.read_csv('Desktop/w266-final-project/pro_china_full_nort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "# source: https://medium.com/analytics-vidhya/text-classification-using-word-embeddings-and-deep-learning-in-python-classifying-tweets-from-6fe644fcfc81\n",
    "def clean_text(\n",
    "    string: str, \n",
    "    punctuations=r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~''',\n",
    "        stop_words = nltk.corpus.stopwords.words(\"english\")) -> str:\n",
    "    \"\"\"\n",
    "    A method to clean text \n",
    "    \"\"\"\n",
    "    # Clean urls\n",
    "    string = re.sub('@[^\\s]+','',string)\n",
    "    string = re.sub('#[^\\s]+','',string)\n",
    "\n",
    "    string = re.sub(r'https?://\\S+|www\\.\\S+', '', string)\n",
    "    string = re.sub(r'<.*?>', '', string)\n",
    "    \n",
    "    #remove random char... non-letters\n",
    "    string = re.sub(r'[^a-zA-Z0-9 -]','', string)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Remove words containing numbers \n",
    "    string = re.sub(\"\\S*\\d\\S*\", '', string).strip()\n",
    "    \n",
    "    # Remove the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "\n",
    "    # Converting the text to lower\n",
    "    string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "    string = ' '.join([word for word in string.split() if word not in stop_words])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "    \n",
    "    string = re.sub(r'rt ','', string)\n",
    "\n",
    "    return string   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_china['text'] = [clean_text(x) for x in pro_china['text']]\n",
    "all_china['text'] = [clean_text(x) for x in all_china['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 sets of tweets \n",
    "is_ccp = pro_china.loc[pro_china['is_ccp']==1]['text']\n",
    "pro_china = pro_china.loc[pro_china['is_ccp']==0]['text']\n",
    "all_china = all_china.loc[all_china['is_ccp']==0]['text']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_list = [is_ccp, pro_china, all_china]\n",
    "\n",
    "def filter_tweets(df, query):\n",
    "    # takes in a list of tweets and then returns a list of new stuff i guess \n",
    "    return df[df.str.contains(query, case=False)]\n",
    "\n",
    "def sentiment_ratio(tweets):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for tweet in tweets:\n",
    "        if sia.polarity_scores(tweet)[\"compound\"] > 0:\n",
    "            positive += 1 \n",
    "        else:\n",
    "            negative +=1 \n",
    "    print(len(tweets), \" tweets\")\n",
    "    return [negative / len(tweets), positive / len(tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5012  tweets\n",
      "12258  tweets\n",
      "6579  tweets\n",
      "Query: China\n",
      "is_ccp: [0.6516360734237829, 0.34836392657621706]\n",
      "pro_china: [0.579295154185022, 0.42070484581497797]\n",
      "all_china: [0.6438668490652075, 0.35613315093479253]\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment_ratio_for_query(query, input_list):\n",
    "    lst = [sentiment_ratio(filter_tweets(i, query)) for i in input_list]\n",
    "    print(\"Query:\", query)\n",
    "    print(\"is_ccp:\", lst[0])\n",
    "    print(\"pro_china:\", lst[1])\n",
    "    print(\"all_china:\", lst[2])\n",
    "\n",
    "\n",
    "results= get_sentiment_ratio_for_query(\"China\", df_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70  tweets\n",
      "255  tweets\n",
      "285  tweets\n",
      "Query: taiwan\n",
      "is_ccp: [0.7142857142857143, 0.2857142857142857]\n",
      "pro_china: [0.5764705882352941, 0.4235294117647059]\n",
      "all_china: [0.6385964912280702, 0.36140350877192984]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"taiwan\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46  tweets\n",
      "278  tweets\n",
      "66  tweets\n",
      "Query: xi jinping\n",
      "is_ccp: [0.8043478260869565, 0.1956521739130435]\n",
      "pro_china: [0.46402877697841727, 0.5359712230215827]\n",
      "all_china: [0.7272727272727273, 0.2727272727272727]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"xi jinping\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70  tweets\n",
      "255  tweets\n",
      "285  tweets\n",
      "Query: taiwan\n",
      "is_ccp: [0.7142857142857143, 0.2857142857142857]\n",
      "pro_china: [0.5764705882352941, 0.4235294117647059]\n",
      "all_china: [0.6385964912280702, 0.36140350877192984]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"taiwan\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5610  tweets\n",
      "1024  tweets\n",
      "3287  tweets\n",
      "Query: xinjiang\n",
      "is_ccp: [0.5775401069518716, 0.42245989304812837]\n",
      "pro_china: [0.646484375, 0.353515625]\n",
      "all_china: [0.6924247033769395, 0.30757529662306055]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"xinjiang\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192  tweets\n",
      "410  tweets\n",
      "608  tweets\n",
      "Query: uyghur\n",
      "is_ccp: [0.3385416666666667, 0.6614583333333334]\n",
      "pro_china: [0.6926829268292682, 0.3073170731707317]\n",
      "all_china: [0.7154605263157895, 0.2845394736842105]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"uyghur\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192  tweets\n",
      "410  tweets\n",
      "608  tweets\n",
      "Query: uyghur\n",
      "is_ccp: [0.3385416666666667, 0.6614583333333334]\n",
      "pro_china: [0.6926829268292682, 0.3073170731707317]\n",
      "all_china: [0.7154605263157895, 0.2845394736842105]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"uyghur\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5012  tweets\n",
      "12258  tweets\n",
      "6579  tweets\n",
      "Query: china\n",
      "is_ccp: [0.6516360734237829, 0.34836392657621706]\n",
      "pro_china: [0.579295154185022, 0.42070484581497797]\n",
      "all_china: [0.6438668490652075, 0.35613315093479253]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"china\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  tweets\n",
      "43  tweets\n",
      "49  tweets\n",
      "Query: surveillance\n",
      "is_ccp: [1.0, 0.0]\n",
      "pro_china: [0.6511627906976745, 0.3488372093023256]\n",
      "all_china: [0.4489795918367347, 0.5510204081632653]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"surveillance\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26  tweets\n",
      "704  tweets\n",
      "404  tweets\n",
      "Query: russia\n",
      "is_ccp: [0.34615384615384615, 0.6538461538461539]\n",
      "pro_china: [0.6193181818181818, 0.3806818181818182]\n",
      "all_china: [0.6089108910891089, 0.3910891089108911]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"russia\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999  tweets\n",
      "822  tweets\n",
      "3888  tweets\n",
      "Query: hong kong\n",
      "is_ccp: [0.6913456728364182, 0.30865432716358177]\n",
      "pro_china: [0.5924574209245742, 0.4075425790754258]\n",
      "all_china: [0.6072530864197531, 0.39274691358024694]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"hong kong\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438  tweets\n",
      "4  tweets\n",
      "3520  tweets\n",
      "Query: wengui\n",
      "is_ccp: [0.6981919332406119, 0.30180806675938804]\n",
      "pro_china: [0.5, 0.5]\n",
      "all_china: [0.6991477272727272, 0.3008522727272727]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"wengui\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cambridge analytica bannon mastermind stuff definitely played areas specifically hunter biden laptop op antichina far right talking point engine largely mastermind also worth looking funder guo wengui\n",
      "website gnews first leak data hunter laptop appendage gtv coowned steve bannon guo wengui\n",
      "last week american rightwing political agitator steve bannon joined tweeting exiled businessman guo wengui former soccer star hao haidong make video calling downfall chinese communist party rather bizarre\n",
      "clear case influencing us election collusion foreign actors hong kongs apple daily fugitive chinese billionaire guo wengui maybe time arrest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in [filter_tweets(i, \"wengui\") for i in df_list][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Downloads/test.csv')\n",
    "test = test.loc[test['is_ccp']==0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19328    RT @WendySiegelman: @JamieMCorey @RepublicanAG...\n",
      "19330    5 potential solutions for maintaining attorney...\n",
      "19340    RT @Stephan59317911: Stephen K. Bannon and Wen...\n",
      "19353    Guo Wengui is a hitting dog https://t.co/FKSI5...\n",
      "19364    RT @karolcummins: @DemopJ Mr. Blair &amp; Stev...\n",
      "                               ...                        \n",
      "38599    @MirqIFHbgcyBzLJ Guo Wengui and Bannon only wa...\n",
      "38613    RT @Tiger789: 郭骗(aka Guo wengui,Miles Kwok,Kwo...\n",
      "38619              @SweetZ55865791 Guo Wengui is a pet dog\n",
      "38621    @mamnoon @JDiamond1 My understanding is that t...\n",
      "38637    RT @ScottMStedman: Steve Bannon is under feder...\n",
      "Name: text, Length: 3164, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in [filter_tweets(i, \"wengui\") for i in [test]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19329    mlb boycotts georgia signs new deal chinese fi...\n",
      "19330    tomorrow hong kongthe national championship vs...\n",
      "19331    hong kong polices deputy commissioner oscar kw...\n",
      "19335    mlb boycotts georgia signs new deal chinese fi...\n",
      "19344    hong kong long trumpeted one transparent regis...\n",
      "                               ...                        \n",
      "38626    musical easter gift microsoft asiapacific work...\n",
      "38637    mlb boycotts georgia signs new deal chinese fi...\n",
      "38640    convictions hong kongs ardent protectors right...\n",
      "38641    mlb boycotts georgia signs new deal chinese fi...\n",
      "38642                                 brave hong kong soul\n",
      "Name: text, Length: 3475, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in [filter_tweets(i, \"hong kong\") for i in [all_china]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  tweets\n",
      "302  tweets\n",
      "204  tweets\n",
      "Query: covid\n",
      "is_ccp: [0.875, 0.125]\n",
      "pro_china: [0.6986754966887417, 0.30132450331125826]\n",
      "all_china: [0.8921568627450981, 0.10784313725490197]\n"
     ]
    }
   ],
   "source": [
    "get_sentiment_ratio_for_query(\"covid\", df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ccp_samples = pd.DataFrame(is_ccp.sample(1000))\n",
    "is_ccp_samples['label'] = \"is_ccp\"\n",
    "pro_china_samples = pd.DataFrame(pro_china.sample(1000))\n",
    "pro_china_samples['label'] = \"pro_china\"\n",
    "all_china_samples = pd.DataFrame(all_china.sample(1000))\n",
    "all_china_samples['label'] = \"all_china\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23584</th>\n",
       "      <td>@_Expanded_Mind_ @ErwinBoydens @GretaThunberg ...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34095</th>\n",
       "      <td>When our companies sourced labor in China it u...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21802</th>\n",
       "      <td>It’s like the world following china on Muslims</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>@BooreamFrancois And one of the highest % of e...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31218</th>\n",
       "      <td>@MeganMargKing @Kollerkunzultz I am ashamed to...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31056</th>\n",
       "      <td>I remember seeing this years ago...\\nStill a s...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27671</th>\n",
       "      <td>@JMichaelWaller Guo wengui is a disgusting per...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31270</th>\n",
       "      <td>@evander_87 @ggreenwald He took millions of do...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21524</th>\n",
       "      <td>@Lonelystarrd22 @The_Acumen @gol_mia Not in Ja...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22196</th>\n",
       "      <td>@sewsweetpink @BBCWorld Really because last ti...</td>\n",
       "      <td>all_china</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      label\n",
       "23584  @_Expanded_Mind_ @ErwinBoydens @GretaThunberg ...  all_china\n",
       "34095  When our companies sourced labor in China it u...  all_china\n",
       "21802     It’s like the world following china on Muslims  all_china\n",
       "24349  @BooreamFrancois And one of the highest % of e...  all_china\n",
       "31218  @MeganMargKing @Kollerkunzultz I am ashamed to...  all_china\n",
       "...                                                  ...        ...\n",
       "31056  I remember seeing this years ago...\\nStill a s...  all_china\n",
       "27671  @JMichaelWaller Guo wengui is a disgusting per...  all_china\n",
       "31270  @evander_87 @ggreenwald He took millions of do...  all_china\n",
       "21524  @Lonelystarrd22 @The_Acumen @gol_mia Not in Ja...  all_china\n",
       "22196  @sewsweetpink @BBCWorld Really because last ti...  all_china\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = pd.concat([is_ccp_samples,pro_china_samples,all_china_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples.to_csv('Desktop/w266-final-project/classify_samples_nort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
