{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9eb11499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0d023162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0cf526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../bertweet_embeddings/' + dataset + '_china_full_nort.csv')\n",
    "tweets = tweets.dropna().reset_index() # some rows come in as blank so they need to be dropped - also need to reset index so they can match embeddings later\n",
    "\n",
    "train, test = train_test_split(tweets, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0c862ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38733, 768]) (38733, 4)\n"
     ]
    }
   ],
   "source": [
    "# reading in tensors from file\n",
    "\n",
    "embeddings = torch.Tensor()\n",
    "\n",
    "for i in range(39):\n",
    "    filename = \"../bertweet_embeddings/embeddings/\" + dataset + \"_china_embedding_\" + str(i*1000) + \".pt\"\n",
    "    embeddings = torch.cat((embeddings, torch.load(filename)))\n",
    "    \n",
    "print(embeddings.shape, tweets.shape) # these should be in agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4365d728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30986, 768) (30986,)\n"
     ]
    }
   ],
   "source": [
    "X_train = embeddings[train.index].detach().numpy()\n",
    "y_train = train['is_ccp']\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de265549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7747, 768) (7747,)\n"
     ]
    }
   ],
   "source": [
    "X_test = embeddings[test.index].detach().numpy()\n",
    "y_test = test['is_ccp']\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2fe4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adagrad = keras.Sequential()\n",
    "model_adagrad.add(keras.layers.Dense(16, \n",
    "                             activation = 'relu'))\n",
    "\n",
    "model_adagrad.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "model_adagrad.compile(optimizer='adagrad',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e978b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_model(num_dense_layers, num_units):\n",
    "    model = keras.Sequential()\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(keras.layers.Dense(num_units, \n",
    "                                     activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c34a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_dropout_model(d):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(16, \n",
    "                                 activation = 'relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42d9947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_conv_model(filters, kernel_size, strides):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Reshape((1, 768)))\n",
    "    model.add(keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, input_shape=(1, 768), padding='same'))\n",
    "    model.add(keras.layers.Dense(16, \n",
    "                                 activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9da9aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_avgpool_model(pool_size, strides):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Reshape((1, 768)))\n",
    "    model.add(keras.layers.AveragePooling1D(pool_size=pool_size, strides=strides, input_shape=(1, 768), padding='same'))\n",
    "    model.add(keras.layers.Dense(16, \n",
    "                                 activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d54538d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_model(model, model_name, epochs=20, i=0):\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train, epochs=epochs)\n",
    "    end = time.time()\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_bool = np.where(y_pred >= 0.5, 1, 0).ravel() #DIY function to round outputs to 0 or 1\n",
    "\n",
    "    cr = classification_report(y_test, y_pred_bool, output_dict=True, digits=4)\n",
    "    #print(confusion_matrix(y_test, y_pred_bool))\n",
    "    \n",
    "    scores = pd.DataFrame({'training_time': [end - start],\n",
    "                           'precision': cr['weighted avg']['precision'],\n",
    "                           'recall' : cr['weighted avg']['recall'],\n",
    "                           'f1' : cr['weighted avg']['f1-score']}, index = [model_name])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "058fc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_evaluate_models(model_dict):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for model_name in model_dict:\n",
    "        results = pd.concat([results, fit_and_score_model(model_dict[model_name], model_name)])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "953555d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8685\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2420 - accuracy: 0.9077\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9176\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2111 - accuracy: 0.9211\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2019 - accuracy: 0.9251\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1971 - accuracy: 0.9271\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1903 - accuracy: 0.9294\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1845 - accuracy: 0.9313\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9336\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1741 - accuracy: 0.9356\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1712 - accuracy: 0.9361\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1670 - accuracy: 0.9366\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1628 - accuracy: 0.9382\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1583 - accuracy: 0.9409\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1522 - accuracy: 0.9433\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1503 - accuracy: 0.9439\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1457 - accuracy: 0.9452\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1434 - accuracy: 0.9475\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1410 - accuracy: 0.9475\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1400 - accuracy: 0.9471: 0s\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2966 - accuracy: 0.8829\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9139\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2096 - accuracy: 0.9197\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1927 - accuracy: 0.9281\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1819 - accuracy: 0.9303\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1684 - accuracy: 0.9366\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1590 - accuracy: 0.9407\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1510 - accuracy: 0.9427\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1430 - accuracy: 0.9467\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1335 - accuracy: 0.9511\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1281 - accuracy: 0.9525\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9548\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1175 - accuracy: 0.9572\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9586\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1094 - accuracy: 0.9599\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9629\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0976 - accuracy: 0.9653\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9658\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9681\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0868 - accuracy: 0.9682\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2899 - accuracy: 0.8803\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2125 - accuracy: 0.9199\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1854 - accuracy: 0.9299\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1677 - accuracy: 0.9365\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1539 - accuracy: 0.9431\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1397 - accuracy: 0.9479\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1305 - accuracy: 0.9507\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1199 - accuracy: 0.9570\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1156 - accuracy: 0.9570\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1058 - accuracy: 0.9609\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0984 - accuracy: 0.9638\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0936 - accuracy: 0.9658\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.9680\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.9711\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.9705\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.9741\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0677 - accuracy: 0.9757\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0673 - accuracy: 0.9752\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0627 - accuracy: 0.9776\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0555 - accuracy: 0.9800\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2855 - accuracy: 0.8845\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2168 - accuracy: 0.9178\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1942 - accuracy: 0.9265\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9351\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1584 - accuracy: 0.9406\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1444 - accuracy: 0.9464\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1340 - accuracy: 0.9502\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1268 - accuracy: 0.9536\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9552\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1118 - accuracy: 0.9589\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9614\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9622\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9629\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9646\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9668\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0867 - accuracy: 0.9677\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0845 - accuracy: 0.9698\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0805 - accuracy: 0.9711\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0774 - accuracy: 0.9715\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0742 - accuracy: 0.9725\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.2630 - accuracy: 0.8946\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 3s 3ms/step - loss: 0.2022 - accuracy: 0.9213\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1677 - accuracy: 0.9366\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 3ms/step - loss: 0.1559 - accuracy: 0.9414\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 3ms/step - loss: 0.1401 - accuracy: 0.9482\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 3ms/step - loss: 0.1309 - accuracy: 0.9520\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 3ms/step - loss: 0.1232 - accuracy: 0.9526\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.1151 - accuracy: 0.9574\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.1053 - accuracy: 0.9612\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1063 - accuracy: 0.9606\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0969 - accuracy: 0.9639\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.9662\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.9668\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.9694\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 3ms/step - loss: 0.0803 - accuracy: 0.9709\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.9703\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.0741 - accuracy: 0.9727\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.0703 - accuracy: 0.9744\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 3s 4ms/step - loss: 0.0657 - accuracy: 0.9751\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 3ms/step - loss: 0.0655 - accuracy: 0.9762\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3530 - accuracy: 0.8579\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2600 - accuracy: 0.9014\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2369 - accuracy: 0.9108\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2204 - accuracy: 0.9185\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2074 - accuracy: 0.9236\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1992 - accuracy: 0.9265\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1927 - accuracy: 0.9282\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1873 - accuracy: 0.9309\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1804 - accuracy: 0.9346\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1765 - accuracy: 0.9359\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1735 - accuracy: 0.9356\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1710 - accuracy: 0.9377\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1649 - accuracy: 0.9393\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1652 - accuracy: 0.9384\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1633 - accuracy: 0.9400\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1588 - accuracy: 0.9414\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1568 - accuracy: 0.9430\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1570 - accuracy: 0.9424\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1529 - accuracy: 0.9438\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1498 - accuracy: 0.9443\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3618 - accuracy: 0.8531\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2621 - accuracy: 0.9007\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2377 - accuracy: 0.9110\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2219 - accuracy: 0.9171\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2101 - accuracy: 0.9219\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1985 - accuracy: 0.9263\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1919 - accuracy: 0.9299\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1860 - accuracy: 0.9307\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.9340\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1735 - accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1701 - accuracy: 0.9365\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1688 - accuracy: 0.9377\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1642 - accuracy: 0.9398\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1605 - accuracy: 0.9401: 0s - loss: 0.1595 - accu\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1608 - accuracy: 0.9401\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1575 - accuracy: 0.9402\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1529 - accuracy: 0.9433\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1507 - accuracy: 0.9441\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1513 - accuracy: 0.9438\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1482 - accuracy: 0.9446\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3464 - accuracy: 0.8592\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2533 - accuracy: 0.9027\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2279 - accuracy: 0.9151\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2129 - accuracy: 0.9218\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2050 - accuracy: 0.9241\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1972 - accuracy: 0.9267\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1891 - accuracy: 0.9301\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1820 - accuracy: 0.9328\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.9351\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1725 - accuracy: 0.9361\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1680 - accuracy: 0.9361\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1637 - accuracy: 0.9406\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1615 - accuracy: 0.9391\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9409\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1547 - accuracy: 0.9426\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1522 - accuracy: 0.9433\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1481 - accuracy: 0.9449\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1470 - accuracy: 0.9455\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1436 - accuracy: 0.9458\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1445 - accuracy: 0.9467\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3284 - accuracy: 0.8672\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2377 - accuracy: 0.9098\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2170 - accuracy: 0.9201\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2089 - accuracy: 0.9223\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2011 - accuracy: 0.9256\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1956 - accuracy: 0.9285\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1914 - accuracy: 0.9287\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1891 - accuracy: 0.9304\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1834 - accuracy: 0.9323\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1813 - accuracy: 0.9321\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1780 - accuracy: 0.9338\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1739 - accuracy: 0.9349\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1720 - accuracy: 0.9353\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1671 - accuracy: 0.9382: 0s - loss: 0.1672 - accuracy: 0.\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1638 - accuracy: 0.9384\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1636 - accuracy: 0.9391\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1603 - accuracy: 0.9403\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1573 - accuracy: 0.9427\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1560 - accuracy: 0.9419\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1522 - accuracy: 0.9432\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3368 - accuracy: 0.8621\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2401 - accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2195 - accuracy: 0.9176\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2090 - accuracy: 0.9222\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2029 - accuracy: 0.9248\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1952 - accuracy: 0.9287\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1899 - accuracy: 0.9293\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1851 - accuracy: 0.9314\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1798 - accuracy: 0.9332\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.9342\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1708 - accuracy: 0.9364\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1668 - accuracy: 0.9396\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1612 - accuracy: 0.9407\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1608 - accuracy: 0.9403\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1544 - accuracy: 0.9438\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1498 - accuracy: 0.9443\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1453 - accuracy: 0.9468\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1401 - accuracy: 0.9490\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1357 - accuracy: 0.9509\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1339 - accuracy: 0.9517\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3251 - accuracy: 0.8720\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2370 - accuracy: 0.9097\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2163 - accuracy: 0.9185\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2063 - accuracy: 0.9228\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1991 - accuracy: 0.9255\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1937 - accuracy: 0.9283\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1851 - accuracy: 0.9316\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1810 - accuracy: 0.9326\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.9347\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1738 - accuracy: 0.9366\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1664 - accuracy: 0.9387\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1627 - accuracy: 0.9397\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1574 - accuracy: 0.9408\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1516 - accuracy: 0.9447\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1475 - accuracy: 0.9462\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9481\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1391 - accuracy: 0.9489\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1362 - accuracy: 0.9494: 0s - loss: 0.1376 - accura\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1332 - accuracy: 0.9513\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1283 - accuracy: 0.9537\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3370 - accuracy: 0.8658\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2394 - accuracy: 0.9097\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2191 - accuracy: 0.9177\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2098 - accuracy: 0.9219\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2002 - accuracy: 0.9257\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1981 - accuracy: 0.9265\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1929 - accuracy: 0.9283\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1872 - accuracy: 0.9305\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1854 - accuracy: 0.9315\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1830 - accuracy: 0.9322\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1805 - accuracy: 0.9326\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1787 - accuracy: 0.9334\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1782 - accuracy: 0.9330\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1753 - accuracy: 0.9337\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1746 - accuracy: 0.9349\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1696 - accuracy: 0.9371\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.9386\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1671 - accuracy: 0.9382\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1653 - accuracy: 0.9383\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1652 - accuracy: 0.9385\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3412 - accuracy: 0.8651\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9066\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2208 - accuracy: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.9218\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2017 - accuracy: 0.9253\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1967 - accuracy: 0.9266\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1931 - accuracy: 0.9291\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1877 - accuracy: 0.9312\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1815 - accuracy: 0.9328\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1783 - accuracy: 0.9341\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1726 - accuracy: 0.9365\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1677 - accuracy: 0.9387\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1635 - accuracy: 0.9391\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.9394\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.9423\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1512 - accuracy: 0.9441\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1509 - accuracy: 0.9443\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1459 - accuracy: 0.9456\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9466\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.9473\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3327 - accuracy: 0.8604\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9131\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2126 - accuracy: 0.9199\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2063 - accuracy: 0.9238\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1967 - accuracy: 0.9283\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1936 - accuracy: 0.9275\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1899 - accuracy: 0.9307\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1879 - accuracy: 0.9308\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1844 - accuracy: 0.9320\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1838 - accuracy: 0.9318\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1800 - accuracy: 0.9333\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1788 - accuracy: 0.9346\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1745 - accuracy: 0.9353\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9361\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1704 - accuracy: 0.9357\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1678 - accuracy: 0.9367\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1661 - accuracy: 0.9374\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1678 - accuracy: 0.9363\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1645 - accuracy: 0.9381\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9384\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 3s 2ms/step - loss: 0.3220 - accuracy: 0.8665\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2306 - accuracy: 0.9116\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2167 - accuracy: 0.9186\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2048 - accuracy: 0.9240\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1994 - accuracy: 0.9255\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1950 - accuracy: 0.9273\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1926 - accuracy: 0.9282\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1900 - accuracy: 0.9300\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1862 - accuracy: 0.9317\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1850 - accuracy: 0.9322\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1839 - accuracy: 0.9325\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1849 - accuracy: 0.9326\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1817 - accuracy: 0.9326\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1794 - accuracy: 0.9355\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1778 - accuracy: 0.9342\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1761 - accuracy: 0.9349\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1765 - accuracy: 0.9347\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1731 - accuracy: 0.9361\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1719 - accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1708 - accuracy: 0.9378\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.3261 - accuracy: 0.8645\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2303 - accuracy: 0.9123\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9193\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2028 - accuracy: 0.9238\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2009 - accuracy: 0.9248\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1927 - accuracy: 0.9285\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1900 - accuracy: 0.9299\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1873 - accuracy: 0.9289\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1803 - accuracy: 0.9336\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1791 - accuracy: 0.9328\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1754 - accuracy: 0.9346\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1711 - accuracy: 0.9355\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1702 - accuracy: 0.9347\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1662 - accuracy: 0.9358\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1635 - accuracy: 0.9384\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1612 - accuracy: 0.9394\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1592 - accuracy: 0.9398\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1562 - accuracy: 0.9413\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1550 - accuracy: 0.9415\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1486 - accuracy: 0.9441\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 3s 2ms/step - loss: 0.3130 - accuracy: 0.8699\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2223 - accuracy: 0.9167\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2074 - accuracy: 0.9223\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1983 - accuracy: 0.9262\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1972 - accuracy: 0.9277\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1911 - accuracy: 0.9289\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1889 - accuracy: 0.9295\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1858 - accuracy: 0.9302\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1793 - accuracy: 0.9318\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1744 - accuracy: 0.9342\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1720 - accuracy: 0.9354\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1673 - accuracy: 0.9376\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1640 - accuracy: 0.9382\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1636 - accuracy: 0.9378\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1554 - accuracy: 0.9418\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1530 - accuracy: 0.9422\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9426\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1455 - accuracy: 0.9448\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1409 - accuracy: 0.9464\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1390 - accuracy: 0.9477\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.3255 - accuracy: 0.8671\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.2304 - accuracy: 0.9115\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9181\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2039 - accuracy: 0.9240\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.2012 - accuracy: 0.9254\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1952 - accuracy: 0.9287\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1956 - accuracy: 0.9269\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.9299\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1860 - accuracy: 0.9320\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1853 - accuracy: 0.9319\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9329\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.9331\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9345\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9344\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.9347\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9356\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1761 - accuracy: 0.9352\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9371\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1718 - accuracy: 0.9380\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1700 - accuracy: 0.9364\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.6551 - accuracy: 0.7346\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6028 - accuracy: 0.8150\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5599 - accuracy: 0.8274\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.5248 - accuracy: 0.8346\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4941 - accuracy: 0.8408\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8445\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4503 - accuracy: 0.8475: 0s - los\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4346 - accuracy: 0.8508\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4215 - accuracy: 0.8526\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4104 - accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8568\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8588: 0s - loss: 0.3929 - accura\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3852 - accuracy: 0.8605\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8616\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3729 - accuracy: 0.8629\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3677 - accuracy: 0.8643\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3629 - accuracy: 0.8648\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3585 - accuracy: 0.8659\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3545 - accuracy: 0.8666\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3508 - accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'baseline': create_dense_model(1, 16),\n",
    "             'dense_1_64': create_dense_model(1, 64),\n",
    "             'dense_1_256': create_dense_model(1, 256),\n",
    "             'dense_2_64': create_dense_model(2, 64),\n",
    "             'dense_2_256': create_dense_model(2, 256),\n",
    "             'dropout_0.1': create_simple_dropout_model(0.1),\n",
    "             'dropout_0.2': create_simple_dropout_model(0.2),\n",
    "             'dropout_0.3': create_simple_dropout_model(0.3),\n",
    "             'avgpool_3_None': create_simple_avgpool_model(3, None),\n",
    "             'avgpool_5_None': create_simple_avgpool_model(5, None),\n",
    "             'avgpool_7_None': create_simple_avgpool_model(7, None),\n",
    "             'avgpool_3_1': create_simple_avgpool_model(3, 1),\n",
    "             'avgpool_5_2': create_simple_avgpool_model(5, 2),\n",
    "             'convolution_3_3_1': create_simple_conv_model(3, 3, 1),\n",
    "             'convolution_5_5_1': create_simple_conv_model(5, 5, 1),\n",
    "             'convolution_7_5_1': create_simple_conv_model(7, 5, 1),\n",
    "             'convolution_5_7_1': create_simple_conv_model(5, 7, 1),\n",
    "             'convolution_3_3_3': create_simple_conv_model(3, 3, 3),\n",
    "             'optimizer_adagrad': model_adagrad}\n",
    "\n",
    "model_performance = bulk_evaluate_models(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b458ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>41.353655</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.948367</td>\n",
       "      <td>0.948366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_1_64</th>\n",
       "      <td>41.408797</td>\n",
       "      <td>0.959203</td>\n",
       "      <td>0.958823</td>\n",
       "      <td>0.958809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_1_256</th>\n",
       "      <td>36.514213</td>\n",
       "      <td>0.963183</td>\n",
       "      <td>0.962695</td>\n",
       "      <td>0.962680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_2_64</th>\n",
       "      <td>41.393924</td>\n",
       "      <td>0.958546</td>\n",
       "      <td>0.958306</td>\n",
       "      <td>0.958305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_2_256</th>\n",
       "      <td>51.394414</td>\n",
       "      <td>0.960759</td>\n",
       "      <td>0.960759</td>\n",
       "      <td>0.960759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_0.1</th>\n",
       "      <td>41.379856</td>\n",
       "      <td>0.948756</td>\n",
       "      <td>0.948625</td>\n",
       "      <td>0.948617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_0.2</th>\n",
       "      <td>41.408615</td>\n",
       "      <td>0.948629</td>\n",
       "      <td>0.948625</td>\n",
       "      <td>0.948624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_0.3</th>\n",
       "      <td>41.446591</td>\n",
       "      <td>0.949027</td>\n",
       "      <td>0.947980</td>\n",
       "      <td>0.947938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_3_None</th>\n",
       "      <td>42.020118</td>\n",
       "      <td>0.944610</td>\n",
       "      <td>0.944366</td>\n",
       "      <td>0.944352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_5_None</th>\n",
       "      <td>41.507965</td>\n",
       "      <td>0.948557</td>\n",
       "      <td>0.948496</td>\n",
       "      <td>0.948497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_7_None</th>\n",
       "      <td>41.516109</td>\n",
       "      <td>0.950305</td>\n",
       "      <td>0.950303</td>\n",
       "      <td>0.950304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_3_1</th>\n",
       "      <td>41.535868</td>\n",
       "      <td>0.940433</td>\n",
       "      <td>0.939977</td>\n",
       "      <td>0.939952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_5_2</th>\n",
       "      <td>41.518912</td>\n",
       "      <td>0.946866</td>\n",
       "      <td>0.946818</td>\n",
       "      <td>0.946814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_3_3_1</th>\n",
       "      <td>41.603100</td>\n",
       "      <td>0.932616</td>\n",
       "      <td>0.931328</td>\n",
       "      <td>0.931259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_5_5_1</th>\n",
       "      <td>41.630231</td>\n",
       "      <td>0.932667</td>\n",
       "      <td>0.931199</td>\n",
       "      <td>0.931160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_7_5_1</th>\n",
       "      <td>41.700444</td>\n",
       "      <td>0.945411</td>\n",
       "      <td>0.945011</td>\n",
       "      <td>0.945006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_5_7_1</th>\n",
       "      <td>42.473640</td>\n",
       "      <td>0.948719</td>\n",
       "      <td>0.948625</td>\n",
       "      <td>0.948626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_3_3_3</th>\n",
       "      <td>41.564958</td>\n",
       "      <td>0.920275</td>\n",
       "      <td>0.915193</td>\n",
       "      <td>0.914890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_adagrad</th>\n",
       "      <td>41.377837</td>\n",
       "      <td>0.871088</td>\n",
       "      <td>0.871047</td>\n",
       "      <td>0.871049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   training_time  precision    recall        f1\n",
       "baseline               41.353655   0.948370  0.948367  0.948366\n",
       "dense_1_64             41.408797   0.959203  0.958823  0.958809\n",
       "dense_1_256            36.514213   0.963183  0.962695  0.962680\n",
       "dense_2_64             41.393924   0.958546  0.958306  0.958305\n",
       "dense_2_256            51.394414   0.960759  0.960759  0.960759\n",
       "dropout_0.1            41.379856   0.948756  0.948625  0.948617\n",
       "dropout_0.2            41.408615   0.948629  0.948625  0.948624\n",
       "dropout_0.3            41.446591   0.949027  0.947980  0.947938\n",
       "avgpool_3_None         42.020118   0.944610  0.944366  0.944352\n",
       "avgpool_5_None         41.507965   0.948557  0.948496  0.948497\n",
       "avgpool_7_None         41.516109   0.950305  0.950303  0.950304\n",
       "avgpool_3_1            41.535868   0.940433  0.939977  0.939952\n",
       "avgpool_5_2            41.518912   0.946866  0.946818  0.946814\n",
       "convolution_3_3_1      41.603100   0.932616  0.931328  0.931259\n",
       "convolution_5_5_1      41.630231   0.932667  0.931199  0.931160\n",
       "convolution_7_5_1      41.700444   0.945411  0.945011  0.945006\n",
       "convolution_5_7_1      42.473640   0.948719  0.948625  0.948626\n",
       "convolution_3_3_3      41.564958   0.920275  0.915193  0.914890\n",
       "optimizer_adagrad      41.377837   0.871088  0.871047  0.871049"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1e0a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_peak = keras.Sequential()\n",
    "\n",
    "model_peak.add(keras.layers.Reshape((1, 768)))\n",
    "model_peak.add(keras.layers.AveragePooling1D(pool_size=3, strides=None, input_shape=(1, 768), padding='same'))\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation = 'relu'))\n",
    "model_peak.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model_peak.add(keras.layers.Dense(64, activation = 'relu'))\n",
    "model_peak.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model_peak.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "model_peak.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c185a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.3419 - accuracy: 0.8561\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2774 - accuracy: 0.8867\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2602 - accuracy: 0.8961\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2471 - accuracy: 0.8994\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2315 - accuracy: 0.9074\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2198 - accuracy: 0.9137\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2138 - accuracy: 0.9148\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2058 - accuracy: 0.9186\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1996 - accuracy: 0.9225\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1924 - accuracy: 0.9260\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1861 - accuracy: 0.9303\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1851 - accuracy: 0.9287\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1795 - accuracy: 0.9309\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1777 - accuracy: 0.9328\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.9345\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1725 - accuracy: 0.9344\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1648 - accuracy: 0.9364\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1670 - accuracy: 0.9351\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1629 - accuracy: 0.9380\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1621 - accuracy: 0.9393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_peak</th>\n",
       "      <td>41.537659</td>\n",
       "      <td>0.951114</td>\n",
       "      <td>0.950949</td>\n",
       "      <td>0.95094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            training_time  precision    recall       f1\n",
       "model_peak      41.537659   0.951114  0.950949  0.95094"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_peak_performance = bulk_evaluate_models({'model_peak': model_peak})\n",
    "model_peak_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f387f8e",
   "metadata": {},
   "source": [
    "## What Did the Model Get the Most Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e673cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dict['dense_2_64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6255651",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([i for [i] in model.predict(X_test)])\n",
    "y_deltas = y_pred - y_test.array\n",
    "y_deltas_argsort = np.argsort(y_pred_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67feecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was CCP But Model Thought It Wasn't:\n",
      "#1\n",
      "@CGTNOfficial the APSI has long been receiving funds from the US government and arm dealers, and it deliberately smears, vilifies and demonizes China for the investors benefits. https://t.co/znZZytt7KW\n",
      "\n",
      "#2\n",
      "China is not the myth,but always reaching out hand to those in need.\n",
      "\n",
      "#3\n",
      "The final preview of Disney's \"Mulan\" debuts in the Super Bowl. The film tells the story of Mulan's march on the battlefield for his father and eventually becoming a legendary Chinese heroine heroine. https://t.co/d3CljPR3pX\n",
      "\n",
      "#4\n",
      "China, Russia and other authoritarian regimes are strengthening their grip with a new suite of high-tech products. As those spread, even second-tier tyrannies will benefit. https://t.co/yeb9r1oEuj\n",
      "\n",
      "#5\n",
      "@PDChina At least from this video,I don't think there is \"genocide\"\n",
      "https://t.co/LKR5k9UOBW\n",
      "\n",
      "#6\n",
      "A visit to Hotan Night Market: How do #Xinjiang locals feel? https://t.co/aEs5StB6Ql GJMA\n",
      "\n",
      "#7\n",
      "@CryptoUB In 2015 i owned a lot of jordan sneakers and i would leave them in the box and buy counterfeits from china for $25 each and ruin those, the idiot only accepted bitcoin. I guess i paid a couple mill for 10 pairs of fake Jordan's. Who's the idiot again\n",
      "\n",
      "#8\n",
      "A survey shows that 50.3% of the people in China are \"sleepy households\". 5G age is coming, how to use the latest technology of AI to improve sleep, so that our sleep becomes high-quality, even knowledgeable?\n",
      "\n",
      "#9\n",
      "Meghan Markle coffee firm bought oat milk from 'police state' Xinjiang https://t.co/SuMPAp3y6w via @MailOnline\n",
      "\n",
      "#10\n",
      "@MFA_China So sad to watch this. Black life matters. https://t.co/uURjYgbxNh\n",
      "\n",
      "Was Not CCP But Model Thought It Was:\n",
      "#1\n",
      "Some individuals in NW Chinas #Xinjiang Uygur Autonomous Region plan to sue @BBC for producing and spreading rumors on Xinjiang issues SCBH https://t.co/ZE8Psi3dyu\n",
      "\n",
      "#2\n",
      "Xinjiangs counter-terrorism measures protect human rights\n",
      "#xinjiang\n",
      "#Xinjiang\n",
      "https://t.co/uku3PtvUNq @fuck_next https://t.co/QdCESGd8ND\n",
      "\n",
      "#3\n",
      "#Xinjiang Fact check: No demolition of mosques or religious places https://t.co/3OMlMG9rez VGWG\n",
      "\n",
      "#4\n",
      "@Think_Scotland Sir John James Cowperthwaite made it work spectacularly well in post war Hong Kong.\n",
      "\n",
      "#5\n",
      "#NowPlaying: What Is Love By China Paige On #RNBHitsRadio  ~  #ListenLive https://t.co/2eKjhqKGkm\n",
      "\n",
      "#6\n",
      "xinjiang cotton field work https://t.co/25VgeICNs2\n",
      "\n",
      "#7\n",
      "@MLB cannot be trusted.\n",
      "MLB boycotts Georgia, signs new deal with Chinese firm that dropped NBA over execs Hong Kong support\n",
      "\n",
      "https://t.co/ncD0Of3Tkt\n",
      "\n",
      "#8\n",
      "Peoples Government of #Xinjiang #Uygur Autonomous Region on Refuting US Secretary of State Mike Pompeos #Xinjiang-related Lies https://t.co/XXE8IBAM7s \n",
      "\n",
      "#9\n",
      "@withayang You'll get your Chinese when I get my damn catgirl onlyfans\n",
      "\n",
      "#10\n",
      "Chinese government is responsible for the death of over two people world wide with the wuhan virus and there mishandling of it period .!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_results = 10\n",
    "\n",
    "print(\"Was CCP But Model Thought It Wasn't:\")\n",
    "\n",
    "for i in range(num_results):\n",
    "    print(\"#\" + str(i + 1))\n",
    "    print(test.iloc[y_deltas_argsort[i]].text + '\\n')\n",
    "    \n",
    "print(\"Was Not CCP But Model Thought It Was:\")\n",
    "\n",
    "for i in range(num_results):\n",
    "    print(\"#\" + str(i + 1))\n",
    "    print(test.iloc[y_deltas_argsort[-(i+1)]].text + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
