{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9eb11499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d023162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0cf526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../bertweet_embeddings/' + dataset + '_china_full_nort.csv')\n",
    "tweets = tweets.dropna().reset_index() # some rows come in as blank so they need to be dropped - also need to reset index so they can match embeddings later\n",
    "\n",
    "train, test = train_test_split(tweets, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0c862ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38733, 768]) (38733, 4)\n"
     ]
    }
   ],
   "source": [
    "# reading in tensors from file\n",
    "\n",
    "embeddings = torch.Tensor()\n",
    "\n",
    "for i in range(39):\n",
    "    filename = \"../bertweet_embeddings/embeddings/\" + dataset + \"_china_embedding_\" + str(i*1000) + \".pt\"\n",
    "    embeddings = torch.cat((embeddings, torch.load(filename)))\n",
    "    \n",
    "print(embeddings.shape, tweets.shape) # these should be in agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4365d728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30986, 768) (30986,)\n"
     ]
    }
   ],
   "source": [
    "X_train = embeddings[train.index].detach().numpy()\n",
    "y_train = train['is_ccp']\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de265549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7747, 768) (7747,)\n"
     ]
    }
   ],
   "source": [
    "X_test = embeddings[test.index].detach().numpy()\n",
    "y_test = test['is_ccp']\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fe4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adagrad = keras.Sequential()\n",
    "model_adagrad.add(keras.layers.Dense(16, \n",
    "                             activation = 'relu'))\n",
    "\n",
    "model_adagrad.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "model_adagrad.compile(optimizer='adagrad',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e978b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_model(num_dense_layers, num_units):\n",
    "    model = keras.Sequential()\n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(keras.layers.Dense(num_units, \n",
    "                                     activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c34a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_dropout_model(d):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(16, \n",
    "                                 activation = 'relu'))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d9947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_conv_model(filters, kernel_size, strides):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Reshape((1, 768)))\n",
    "    model.add(keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, input_shape=(1, 768), padding='same'))\n",
    "    model.add(keras.layers.Dense(16, \n",
    "                                 activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da9aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_avgpool_model(pool_size, strides):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Reshape((1, 768)))\n",
    "    model.add(keras.layers.AveragePooling1D(pool_size=pool_size, strides=strides, input_shape=(1, 768), padding='same'))\n",
    "    model.add(keras.layers.Dense(16, \n",
    "                                 activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d54538d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_model(model, model_name, epochs=20, i=0):\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train, epochs=epochs)\n",
    "    end = time.time()\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_bool = np.where(y_pred >= 0.5, 1, 0).ravel() #DIY function to round outputs to 0 or 1\n",
    "\n",
    "    cr = classification_report(y_test, y_pred_bool, output_dict=True, digits=4)\n",
    "    #print(confusion_matrix(y_test, y_pred_bool))\n",
    "    \n",
    "    scores = pd.DataFrame({'training_time': [end - start],\n",
    "                           'precision': cr['weighted avg']['precision'],\n",
    "                           'recall' : cr['weighted avg']['recall'],\n",
    "                           'f1' : cr['weighted avg']['f1-score']}, index = [model_name])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "058fc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_evaluate_models(model_dict, epochs=20):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for model_name in model_dict:\n",
    "        results = pd.concat([results, fit_and_score_model(model_dict[model_name], model_name, epochs)])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953555d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2949 - accuracy: 0.8828\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2046 - accuracy: 0.9186\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1845 - accuracy: 0.9270\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1747 - accuracy: 0.9325\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.9336\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1628 - accuracy: 0.9370\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1600 - accuracy: 0.9370\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9405\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1542 - accuracy: 0.9410\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1511 - accuracy: 0.9410\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1476 - accuracy: 0.9432\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1452 - accuracy: 0.9442\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1430 - accuracy: 0.9448\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9452\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1396 - accuracy: 0.9459\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1364 - accuracy: 0.9480\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1353 - accuracy: 0.9482\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1354 - accuracy: 0.9480\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1314 - accuracy: 0.9494\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1303 - accuracy: 0.9494\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2499 - accuracy: 0.8983\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1863 - accuracy: 0.9264\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9338\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1661 - accuracy: 0.9349\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9386\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1541 - accuracy: 0.9391\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9414\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.9456\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1361 - accuracy: 0.9477\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.9508\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1226 - accuracy: 0.9535\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1186 - accuracy: 0.9542\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1143 - accuracy: 0.9578\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9596\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1035 - accuracy: 0.9623\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9637\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0968 - accuracy: 0.9641\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9668\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9665\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0866 - accuracy: 0.9682\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2376 - accuracy: 0.9016\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1830 - accuracy: 0.9274\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1663 - accuracy: 0.9342\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1506 - accuracy: 0.9406\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.9468\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 3s 3ms/step - loss: 0.1272 - accuracy: 0.9504\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1180 - accuracy: 0.9555\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1102 - accuracy: 0.9583\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1046 - accuracy: 0.9611\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0974 - accuracy: 0.9640\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.9674\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.9689\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.9709\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.9709\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.9727\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.9743\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0676 - accuracy: 0.9760\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0612 - accuracy: 0.9786\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0621 - accuracy: 0.9783\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0566 - accuracy: 0.9798\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2450 - accuracy: 0.9002\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1816 - accuracy: 0.9269\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1660 - accuracy: 0.9345\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1467 - accuracy: 0.9423\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1361 - accuracy: 0.9463\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.9511\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9523\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1162 - accuracy: 0.9572\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1093 - accuracy: 0.9577\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.9599\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9630\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0978 - accuracy: 0.9634\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9663\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0860 - accuracy: 0.9681\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0841 - accuracy: 0.9691\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0812 - accuracy: 0.9693\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0751 - accuracy: 0.9722\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0792 - accuracy: 0.9707\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0719 - accuracy: 0.9732\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.0706 - accuracy: 0.9731\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 3s 2ms/step - loss: 0.2224 - accuracy: 0.9073\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1741 - accuracy: 0.9305\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1524 - accuracy: 0.9391\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1354 - accuracy: 0.9462\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1267 - accuracy: 0.9502\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1170 - accuracy: 0.9557\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1097 - accuracy: 0.9582\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1001 - accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.9638\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0938 - accuracy: 0.9653\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.9666\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.9683\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.9696\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.9711\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.9735\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.9729\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0679 - accuracy: 0.9749\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0661 - accuracy: 0.9747\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0628 - accuracy: 0.9768\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.0606 - accuracy: 0.9778\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3145 - accuracy: 0.8733\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2237 - accuracy: 0.9116\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2035 - accuracy: 0.9211\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1869 - accuracy: 0.9294\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1779 - accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1710 - accuracy: 0.9353\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1655 - accuracy: 0.9364\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1607 - accuracy: 0.9399\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1571 - accuracy: 0.9393\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1524 - accuracy: 0.9426\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1493 - accuracy: 0.9441\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1470 - accuracy: 0.9453\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1449 - accuracy: 0.9463\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1426 - accuracy: 0.9470\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1393 - accuracy: 0.9484\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9494\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1380 - accuracy: 0.9484\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1354 - accuracy: 0.9497\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1325 - accuracy: 0.9508: 0s - loss: 0.132\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1322 - accuracy: 0.9520: 0s\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.3405 - accuracy: 0.8643\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2400 - accuracy: 0.9049\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2146 - accuracy: 0.9161\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2003 - accuracy: 0.9212\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9273\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9286\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.9313\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1730 - accuracy: 0.9329\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1682 - accuracy: 0.9347\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1665 - accuracy: 0.9346\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1614 - accuracy: 0.9385\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1584 - accuracy: 0.9376\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1567 - accuracy: 0.9396\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1561 - accuracy: 0.9406\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1539 - accuracy: 0.9403\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1506 - accuracy: 0.9413\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1475 - accuracy: 0.9412\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1472 - accuracy: 0.9430\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1456 - accuracy: 0.9437\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1458 - accuracy: 0.9429\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.8661\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2274 - accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2018 - accuracy: 0.9218\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1915 - accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1827 - accuracy: 0.9302\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1726 - accuracy: 0.9335\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1679 - accuracy: 0.9367\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1626 - accuracy: 0.9388\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1594 - accuracy: 0.9401\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1543 - accuracy: 0.9418: 0s - loss: 0 - ETA: 0s - loss: 0.1550 - \n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1526 - accuracy: 0.9429\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1500 - accuracy: 0.9444\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1454 - accuracy: 0.9464\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1448 - accuracy: 0.9456\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9470\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1428 - accuracy: 0.9469\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1406 - accuracy: 0.9486\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1388 - accuracy: 0.9481\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1346 - accuracy: 0.9512\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1354 - accuracy: 0.9500\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2833 - accuracy: 0.8886\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1987 - accuracy: 0.9205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1798 - accuracy: 0.9297\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1707 - accuracy: 0.9331\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1657 - accuracy: 0.9352\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1597 - accuracy: 0.9381\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1591 - accuracy: 0.9382\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1551 - accuracy: 0.9399\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1528 - accuracy: 0.9424\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1505 - accuracy: 0.9423\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1479 - accuracy: 0.9439\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1479 - accuracy: 0.9439\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1454 - accuracy: 0.9436\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1456 - accuracy: 0.9439\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9456\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1434 - accuracy: 0.9440\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.9462\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1415 - accuracy: 0.9450\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1403 - accuracy: 0.9465\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1387 - accuracy: 0.9466\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2802 - accuracy: 0.8886\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1975 - accuracy: 0.9207\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1799 - accuracy: 0.9295\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1718 - accuracy: 0.9317\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1664 - accuracy: 0.9340\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1639 - accuracy: 0.9370\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1557 - accuracy: 0.9397\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1573 - accuracy: 0.9389\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1535 - accuracy: 0.9413\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1504 - accuracy: 0.9427\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.9429\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.9414\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1479 - accuracy: 0.9428\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1447 - accuracy: 0.9451\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1448 - accuracy: 0.9452\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.9461\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1424 - accuracy: 0.9457\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9455: 0s - loss: 0.143\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1399 - accuracy: 0.9468\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1385 - accuracy: 0.9471\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2817 - accuracy: 0.8841\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2006 - accuracy: 0.9194\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1804 - accuracy: 0.9288\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1716 - accuracy: 0.9328\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1662 - accuracy: 0.9348\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1643 - accuracy: 0.9365\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9384\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1553 - accuracy: 0.9406\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1534 - accuracy: 0.9403\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1506 - accuracy: 0.9413\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1472 - accuracy: 0.9421\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1434 - accuracy: 0.9441\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1420 - accuracy: 0.9454\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.9460\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1352 - accuracy: 0.9485\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1338 - accuracy: 0.9488\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9506\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1280 - accuracy: 0.9513\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1244 - accuracy: 0.9524\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1236 - accuracy: 0.9525\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2744 - accuracy: 0.8906\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1962 - accuracy: 0.9224: 0s - loss: 0.1981 - accuracy\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1813 - accuracy: 0.9286\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1717 - accuracy: 0.9326\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1656 - accuracy: 0.9357\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.9369\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1586 - accuracy: 0.9394\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1551 - accuracy: 0.9396\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1544 - accuracy: 0.9405\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1505 - accuracy: 0.9417\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1492 - accuracy: 0.9428\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1489 - accuracy: 0.9424\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1482 - accuracy: 0.9426\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1465 - accuracy: 0.9440\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1435 - accuracy: 0.9441\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1441 - accuracy: 0.9447\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1428 - accuracy: 0.9454\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9449\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1407 - accuracy: 0.9448\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1404 - accuracy: 0.9458\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2935 - accuracy: 0.8833\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2041 - accuracy: 0.9177\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1834 - accuracy: 0.9276\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.9316\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1684 - accuracy: 0.9347\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1626 - accuracy: 0.9373\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1599 - accuracy: 0.9378\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1562 - accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.9402\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9418\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1484 - accuracy: 0.9422\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1460 - accuracy: 0.9440\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1438 - accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1408 - accuracy: 0.9448\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1405 - accuracy: 0.9462\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1370 - accuracy: 0.9471\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1356 - accuracy: 0.9479\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1347 - accuracy: 0.9477\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1320 - accuracy: 0.9486\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1296 - accuracy: 0.9493\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2843 - accuracy: 0.8878\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1933 - accuracy: 0.9239\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.9308\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.9345\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1641 - accuracy: 0.9363\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1605 - accuracy: 0.9386\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1568 - accuracy: 0.9399\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1555 - accuracy: 0.9405\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1512 - accuracy: 0.9427\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1501 - accuracy: 0.9422\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1485 - accuracy: 0.9429\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1465 - accuracy: 0.9439\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1437 - accuracy: 0.9458\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1421 - accuracy: 0.9451\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1424 - accuracy: 0.9448\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1410 - accuracy: 0.9462\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1403 - accuracy: 0.9469\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1392 - accuracy: 0.9472\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1353 - accuracy: 0.9482\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1377 - accuracy: 0.9469\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2983 - accuracy: 0.8831\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9194\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.9290\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9332\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9367\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1572 - accuracy: 0.9386\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1547 - accuracy: 0.9387\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9416\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9441\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9439\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1404 - accuracy: 0.9448\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1402 - accuracy: 0.9451\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1367 - accuracy: 0.9468\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1346 - accuracy: 0.9486\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9482\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1338 - accuracy: 0.9485\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.9491\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9508\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1293 - accuracy: 0.9491\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1268 - accuracy: 0.9515\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2692 - accuracy: 0.8907\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1873 - accuracy: 0.9264\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1715 - accuracy: 0.9337\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1654 - accuracy: 0.9364\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1562 - accuracy: 0.9397\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1554 - accuracy: 0.9396\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1501 - accuracy: 0.9419\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1474 - accuracy: 0.9421\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1435 - accuracy: 0.9451\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1419 - accuracy: 0.9446\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1375 - accuracy: 0.9470\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1384 - accuracy: 0.9446\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1343 - accuracy: 0.9468\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1322 - accuracy: 0.9472\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1282 - accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1288 - accuracy: 0.9493\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1253 - accuracy: 0.9507\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1229 - accuracy: 0.9519\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 2ms/step - loss: 0.1202 - accuracy: 0.9527\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.2706 - accuracy: 0.8919\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1896 - accuracy: 0.9241\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1742 - accuracy: 0.9332\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1680 - accuracy: 0.9341\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1630 - accuracy: 0.9380\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1588 - accuracy: 0.9391\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1546 - accuracy: 0.9408\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1547 - accuracy: 0.9405\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1517 - accuracy: 0.9414\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1470 - accuracy: 0.9437\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1458 - accuracy: 0.9446\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1437 - accuracy: 0.9448\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1424 - accuracy: 0.9455\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1395 - accuracy: 0.9457\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.9464\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1376 - accuracy: 0.9460\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1341 - accuracy: 0.9478\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1331 - accuracy: 0.9472\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1308 - accuracy: 0.9480\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 2s 2ms/step - loss: 0.1304 - accuracy: 0.9484\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2905 - accuracy: 0.8801\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1977 - accuracy: 0.9204\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1794 - accuracy: 0.9293\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1689 - accuracy: 0.9349\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1666 - accuracy: 0.9366\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1597 - accuracy: 0.9380\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1580 - accuracy: 0.9402\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1535 - accuracy: 0.9406\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1534 - accuracy: 0.9409\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1520 - accuracy: 0.9418\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1483 - accuracy: 0.9432\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1466 - accuracy: 0.9439\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1475 - accuracy: 0.9437\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1452 - accuracy: 0.9450\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1427 - accuracy: 0.9455\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1426 - accuracy: 0.9453\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1416 - accuracy: 0.9474\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1387 - accuracy: 0.9475\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1389 - accuracy: 0.9468\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1403 - accuracy: 0.9460\n",
      "Epoch 1/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.6589 - accuracy: 0.7114\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 995us/step - loss: 0.5836 - accuracy: 0.8426\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 986us/step - loss: 0.5262 - accuracy: 0.8543\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 972us/step - loss: 0.4834 - accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 980us/step - loss: 0.4509 - accuracy: 0.8617\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 986us/step - loss: 0.4256 - accuracy: 0.8637\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 984us/step - loss: 0.4054 - accuracy: 0.8657\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 982us/step - loss: 0.3890 - accuracy: 0.8685\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 982us/step - loss: 0.3753 - accuracy: 0.8708\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3632 - accuracy: 0.8727\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 979us/step - loss: 0.3525 - accuracy: 0.8744\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3434 - accuracy: 0.8759: 0s - loss: 0.3429 - accuracy: 0.\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 996us/step - loss: 0.3356 - accuracy: 0.8771\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 974us/step - loss: 0.3288 - accuracy: 0.87830s - loss: 0.3297 - accuracy\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 970us/step - loss: 0.3229 - accuracy: 0.8796\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3177 - accuracy: 0.8815\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 979us/step - loss: 0.3130 - accuracy: 0.8822\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8825\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3049 - accuracy: 0.8837\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.3014 - accuracy: 0.8848\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'baseline': create_dense_model(1, 16),\n",
    "             'dense_1_64': create_dense_model(1, 64),\n",
    "             'dense_1_256': create_dense_model(1, 256),\n",
    "             'dense_2_64': create_dense_model(2, 64),\n",
    "             'dense_2_256': create_dense_model(2, 256),\n",
    "             'dropout_0.1': create_simple_dropout_model(0.1),\n",
    "             'dropout_0.2': create_simple_dropout_model(0.2),\n",
    "             'dropout_0.3': create_simple_dropout_model(0.3),\n",
    "             'avgpool_3_None': create_simple_avgpool_model(3, None),\n",
    "             'avgpool_5_None': create_simple_avgpool_model(5, None),\n",
    "             'avgpool_7_None': create_simple_avgpool_model(7, None),\n",
    "             'avgpool_3_1': create_simple_avgpool_model(3, 1),\n",
    "             'avgpool_5_2': create_simple_avgpool_model(5, 2),\n",
    "             'convolution_3_3_1': create_simple_conv_model(3, 3, 1),\n",
    "             'convolution_5_5_1': create_simple_conv_model(5, 5, 1),\n",
    "             'convolution_7_5_1': create_simple_conv_model(7, 5, 1),\n",
    "             'convolution_5_7_1': create_simple_conv_model(5, 7, 1),\n",
    "             'convolution_3_3_3': create_simple_conv_model(3, 3, 3),\n",
    "             'optimizer_adagrad': model_adagrad}\n",
    "\n",
    "model_performance = bulk_evaluate_models(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b458ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>41.526285</td>\n",
       "      <td>0.943574</td>\n",
       "      <td>0.943075</td>\n",
       "      <td>0.943054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_1_64</th>\n",
       "      <td>23.608913</td>\n",
       "      <td>0.960653</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.960630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_1_256</th>\n",
       "      <td>37.104236</td>\n",
       "      <td>0.956595</td>\n",
       "      <td>0.955596</td>\n",
       "      <td>0.955567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_2_64</th>\n",
       "      <td>25.238492</td>\n",
       "      <td>0.960245</td>\n",
       "      <td>0.960243</td>\n",
       "      <td>0.960243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense_2_256</th>\n",
       "      <td>46.685268</td>\n",
       "      <td>0.965194</td>\n",
       "      <td>0.965148</td>\n",
       "      <td>0.965148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_0.1</th>\n",
       "      <td>41.368037</td>\n",
       "      <td>0.953392</td>\n",
       "      <td>0.953272</td>\n",
       "      <td>0.953271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_0.2</th>\n",
       "      <td>41.406643</td>\n",
       "      <td>0.945831</td>\n",
       "      <td>0.945785</td>\n",
       "      <td>0.945785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_0.3</th>\n",
       "      <td>41.387655</td>\n",
       "      <td>0.951270</td>\n",
       "      <td>0.951078</td>\n",
       "      <td>0.951075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_3_None</th>\n",
       "      <td>41.492336</td>\n",
       "      <td>0.944509</td>\n",
       "      <td>0.943075</td>\n",
       "      <td>0.943036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_5_None</th>\n",
       "      <td>41.474525</td>\n",
       "      <td>0.946447</td>\n",
       "      <td>0.946173</td>\n",
       "      <td>0.946167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_7_None</th>\n",
       "      <td>41.661712</td>\n",
       "      <td>0.950530</td>\n",
       "      <td>0.950432</td>\n",
       "      <td>0.950431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_3_1</th>\n",
       "      <td>41.476745</td>\n",
       "      <td>0.945215</td>\n",
       "      <td>0.945011</td>\n",
       "      <td>0.945002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgpool_5_2</th>\n",
       "      <td>41.478300</td>\n",
       "      <td>0.935610</td>\n",
       "      <td>0.932490</td>\n",
       "      <td>0.932356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_3_3_1</th>\n",
       "      <td>26.803609</td>\n",
       "      <td>0.942830</td>\n",
       "      <td>0.942300</td>\n",
       "      <td>0.942278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_5_5_1</th>\n",
       "      <td>30.531045</td>\n",
       "      <td>0.947586</td>\n",
       "      <td>0.947464</td>\n",
       "      <td>0.947462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_7_5_1</th>\n",
       "      <td>30.982682</td>\n",
       "      <td>0.951095</td>\n",
       "      <td>0.951078</td>\n",
       "      <td>0.951077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_5_7_1</th>\n",
       "      <td>34.071826</td>\n",
       "      <td>0.945442</td>\n",
       "      <td>0.944107</td>\n",
       "      <td>0.944072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolution_3_3_3</th>\n",
       "      <td>26.792771</td>\n",
       "      <td>0.947063</td>\n",
       "      <td>0.946689</td>\n",
       "      <td>0.946681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_adagrad</th>\n",
       "      <td>20.825278</td>\n",
       "      <td>0.887376</td>\n",
       "      <td>0.886924</td>\n",
       "      <td>0.886900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   training_time  precision    recall        f1\n",
       "baseline               41.526285   0.943574  0.943075  0.943054\n",
       "dense_1_64             23.608913   0.960653  0.960630  0.960630\n",
       "dense_1_256            37.104236   0.956595  0.955596  0.955567\n",
       "dense_2_64             25.238492   0.960245  0.960243  0.960243\n",
       "dense_2_256            46.685268   0.965194  0.965148  0.965148\n",
       "dropout_0.1            41.368037   0.953392  0.953272  0.953271\n",
       "dropout_0.2            41.406643   0.945831  0.945785  0.945785\n",
       "dropout_0.3            41.387655   0.951270  0.951078  0.951075\n",
       "avgpool_3_None         41.492336   0.944509  0.943075  0.943036\n",
       "avgpool_5_None         41.474525   0.946447  0.946173  0.946167\n",
       "avgpool_7_None         41.661712   0.950530  0.950432  0.950431\n",
       "avgpool_3_1            41.476745   0.945215  0.945011  0.945002\n",
       "avgpool_5_2            41.478300   0.935610  0.932490  0.932356\n",
       "convolution_3_3_1      26.803609   0.942830  0.942300  0.942278\n",
       "convolution_5_5_1      30.531045   0.947586  0.947464  0.947462\n",
       "convolution_7_5_1      30.982682   0.951095  0.951078  0.951077\n",
       "convolution_5_7_1      34.071826   0.945442  0.944107  0.944072\n",
       "convolution_3_3_3      26.792771   0.947063  0.946689  0.946681\n",
       "optimizer_adagrad      20.825278   0.887376  0.886924  0.886900"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1e0a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_peak = keras.Sequential()\n",
    "\n",
    "#model_peak.add(keras.layers.Reshape((1, 768)))\n",
    "#model_peak.add(keras.layers.AveragePooling1D(pool_size=3, strides=None, input_shape=(1, 768), padding='same'))\n",
    "\n",
    "model_peak.add(keras.layers.Dense(768, activation = 'relu'))\n",
    "model_peak.add(keras.layers.Dropout(0.05))\n",
    "\n",
    "# model_peak.add(keras.layers.Dense(768, activation = 'relu'))\n",
    "# model_peak.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model_peak.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "model_peak.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c185a780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.2713 - accuracy: 0.8886\n",
      "Epoch 2/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.2091 - accuracy: 0.9205\n",
      "Epoch 3/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1791 - accuracy: 0.9315\n",
      "Epoch 4/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1614 - accuracy: 0.9397\n",
      "Epoch 5/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1477 - accuracy: 0.9452\n",
      "Epoch 6/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1353 - accuracy: 0.9491\n",
      "Epoch 7/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1273 - accuracy: 0.9520\n",
      "Epoch 8/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1180 - accuracy: 0.9564\n",
      "Epoch 9/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1100 - accuracy: 0.9590\n",
      "Epoch 10/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.1023 - accuracy: 0.9632\n",
      "Epoch 11/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0975 - accuracy: 0.9643\n",
      "Epoch 12/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0932 - accuracy: 0.9651\n",
      "Epoch 13/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0856 - accuracy: 0.9689\n",
      "Epoch 14/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0818 - accuracy: 0.9706\n",
      "Epoch 15/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0769 - accuracy: 0.9726\n",
      "Epoch 16/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0709 - accuracy: 0.9745\n",
      "Epoch 17/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0679 - accuracy: 0.9759\n",
      "Epoch 18/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0657 - accuracy: 0.9763\n",
      "Epoch 19/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0622 - accuracy: 0.9779\n",
      "Epoch 20/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0567 - accuracy: 0.9797\n",
      "Epoch 21/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0534 - accuracy: 0.9809\n",
      "Epoch 22/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0510 - accuracy: 0.9813\n",
      "Epoch 23/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0474 - accuracy: 0.9828\n",
      "Epoch 24/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0455 - accuracy: 0.9833\n",
      "Epoch 25/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0411 - accuracy: 0.9852\n",
      "Epoch 26/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0402 - accuracy: 0.9859\n",
      "Epoch 27/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0379 - accuracy: 0.9859\n",
      "Epoch 28/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0356 - accuracy: 0.9874\n",
      "Epoch 29/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0358 - accuracy: 0.9867\n",
      "Epoch 30/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0334 - accuracy: 0.9876\n",
      "Epoch 31/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0312 - accuracy: 0.9886\n",
      "Epoch 32/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0296 - accuracy: 0.9888\n",
      "Epoch 33/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0286 - accuracy: 0.9897\n",
      "Epoch 34/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0262 - accuracy: 0.9907\n",
      "Epoch 35/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0258 - accuracy: 0.9908\n",
      "Epoch 36/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 37/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9922\n",
      "Epoch 38/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0249 - accuracy: 0.9907\n",
      "Epoch 39/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 40/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0206 - accuracy: 0.9933\n",
      "Epoch 41/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0208 - accuracy: 0.9925\n",
      "Epoch 42/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 43/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0219 - accuracy: 0.9922\n",
      "Epoch 44/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0155 - accuracy: 0.9949\n",
      "Epoch 45/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 46/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0180 - accuracy: 0.9932\n",
      "Epoch 47/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0153 - accuracy: 0.9944\n",
      "Epoch 48/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0178 - accuracy: 0.9938\n",
      "Epoch 49/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "Epoch 50/50\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 0.0120 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_peak</th>\n",
       "      <td>202.352844</td>\n",
       "      <td>0.965786</td>\n",
       "      <td>0.965664</td>\n",
       "      <td>0.965659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            training_time  precision    recall        f1\n",
       "model_peak     202.352844   0.965786  0.965664  0.965659"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_peak_performance = bulk_evaluate_models({'model_peak': model_peak}, epochs=50)\n",
    "model_peak_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "865bc099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3807  101]\n",
      " [ 165 3674]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_peak = model_peak.predict(X_test)\n",
    "y_pred_peak_bool = np.where(y_pred_peak >= 0.5, 1, 0).ravel()\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_peak_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f387f8e",
   "metadata": {},
   "source": [
    "## What Did the Model Get the Most Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e673cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6255651",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([i for [i] in model.predict(X_test)])\n",
    "y_pred_deltas = y_pred - y_test.array\n",
    "y_deltas_argsort = np.argsort(y_pred_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67feecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = 20\n",
    "\n",
    "false_negatives = pd.DataFrame(columns=['text', 'probability', 'is_ccp'])\n",
    "\n",
    "for i in range(num_results):\n",
    "    details = pd.DataFrame({'text': test.iloc[y_deltas_argsort[i]].text, 'probability': y_pred[y_deltas_argsort[i]], 'is_ccp': test.iloc[y_deltas_argsort[i]].is_ccp}, index=[i + 1])\n",
    "    false_negatives = pd.concat([false_negatives, details])\n",
    "    \n",
    "false_positives = pd.DataFrame(columns=['text', 'probability', 'is_ccp'])\n",
    "\n",
    "for i in range(num_results):\n",
    "    details = pd.DataFrame({'text': test.iloc[y_deltas_argsort[-(i+1)]].text, 'probability': y_pred[y_deltas_argsort[-(i+1)]], 'is_ccp': test.iloc[y_deltas_argsort[-(i+1)]].is_ccp}, index=[i + 1])\n",
    "    false_positives = pd.concat([false_positives, details])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61e057dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>probability</th>\n",
       "      <th>is_ccp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The West Isnt Ready for the Coming Wave of Ch...</td>\n",
       "      <td>2.191319e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@TonyBrunoShow @KingJames @NBA @nikebasketball...</td>\n",
       "      <td>2.764007e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @AngeloG86207806: 1871 Chinatown massacre\\n...</td>\n",
       "      <td>5.285465e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With Message For China, Dalai Lama Says His Su...</td>\n",
       "      <td>4.031170e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bannon created novel coronavirus conspiracy th...</td>\n",
       "      <td>4.847097e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@RNH00757249 @PDChina Well,I see. https://t.co...</td>\n",
       "      <td>6.274943e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The claim of since 2017, the Chinese governme...</td>\n",
       "      <td>9.810135e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#DrLiMengYan## \\nRumor Press Conference...</td>\n",
       "      <td>1.118966e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#StopXinjiangrumors\\nThis jade expert ident...</td>\n",
       "      <td>2.559877e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@Terry24492280 @OzraeliAvi Since the rising of...</td>\n",
       "      <td>2.807547e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@feig93779016 Go China</td>\n",
       "      <td>4.530666e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@Eazzayyy @NathanRichHGDW And it violates twit...</td>\n",
       "      <td>5.255799e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Farmers are harvesting the pre-Qing Ming Tea i...</td>\n",
       "      <td>9.098718e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A new wave of media reports on Chinese forced ...</td>\n",
       "      <td>1.257774e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@MFA_China So sad to watch this. Black life ma...</td>\n",
       "      <td>1.570851e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @cathiabi: @globaltimesnews @UyghurCongress...</td>\n",
       "      <td>3.226360e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@NicoleS00264634 Credit for other people as th...</td>\n",
       "      <td>4.884214e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@instosammy It is really difficult to try to d...</td>\n",
       "      <td>5.708368e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Huawei: The world's most controversial company...</td>\n",
       "      <td>8.736090e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@czZvHNQPEw8z6Uq The clown is not Taiwan, no m...</td>\n",
       "      <td>1.134712e-04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   probability  is_ccp\n",
       "1   The West Isnt Ready for the Coming Wave of Ch...  2.191319e-08     1.0\n",
       "2   @TonyBrunoShow @KingJames @NBA @nikebasketball...  2.764007e-08     1.0\n",
       "3   RT @AngeloG86207806: 1871 Chinatown massacre\\n...  5.285465e-08     1.0\n",
       "4   With Message For China, Dalai Lama Says His Su...  4.031170e-07     1.0\n",
       "5   Bannon created novel coronavirus conspiracy th...  4.847097e-07     1.0\n",
       "6   @RNH00757249 @PDChina Well,I see. https://t.co...  6.274943e-07     1.0\n",
       "7   The claim of since 2017, the Chinese governme...  9.810135e-07     1.0\n",
       "8   #DrLiMengYan## \\nRumor Press Conference...  1.118966e-06     1.0\n",
       "9   #StopXinjiangrumors\\nThis jade expert ident...  2.559877e-06     1.0\n",
       "10  @Terry24492280 @OzraeliAvi Since the rising of...  2.807547e-06     1.0\n",
       "11                          @feig93779016 Go China  4.530666e-06     1.0\n",
       "12  @Eazzayyy @NathanRichHGDW And it violates twit...  5.255799e-06     1.0\n",
       "13  Farmers are harvesting the pre-Qing Ming Tea i...  9.098718e-06     1.0\n",
       "14  A new wave of media reports on Chinese forced ...  1.257774e-05     1.0\n",
       "15  @MFA_China So sad to watch this. Black life ma...  1.570851e-05     1.0\n",
       "16  RT @cathiabi: @globaltimesnews @UyghurCongress...  3.226360e-05     1.0\n",
       "17  @NicoleS00264634 Credit for other people as th...  4.884214e-05     1.0\n",
       "18  @instosammy It is really difficult to try to d...  5.708368e-05     1.0\n",
       "19  Huawei: The world's most controversial company...  8.736090e-05     1.0\n",
       "20  @czZvHNQPEw8z6Uq The clown is not Taiwan, no m...  1.134712e-04     1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e09b4d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>probability</th>\n",
       "      <th>is_ccp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We pledge: No more tears on our land\\nIn wrath...</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get Lost in a #Snow-Blanketed #Wonderland this...</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VOAChinese The cotton produced in #Xinjiang i...</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@CNBC Liars and terrorism supporters, shame on...</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Men's Curling World Championship: #Scotland be...</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@hoopstingley @Vanilla3087 @TrueNorthCentre @T...</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@lukedepulford @RazvenHK Hong Kong is vibrant,...</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A look at Langzhong ancient city in Nanchong, ...</td>\n",
       "      <td>0.997336</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It should be noted that Hong Kong is facing mu...</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#CyberAttack on Inter Parliamentary Alliance o...</td>\n",
       "      <td>0.995130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>China's Tianwen-1 spacecraft captures stunning...</td>\n",
       "      <td>0.994811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@Flufferbot2 @redsteeze Why not follow #Disney...</td>\n",
       "      <td>0.994390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Youtuber : a group of young people from across...</td>\n",
       "      <td>0.994191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Challenges of fighting terrorism in Xinjiang -...</td>\n",
       "      <td>0.993676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mr. Wenguis latest short video: Brothers and ...</td>\n",
       "      <td>0.990723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#India and #China need to strengthen confidenc...</td>\n",
       "      <td>0.988538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@ejXyYC69uapCC7q Don't let Guo Wengui influenc...</td>\n",
       "      <td>0.983925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@btslabs_china @ICOboosterteam @ICO_Analytics ...</td>\n",
       "      <td>0.979023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>#Xinjiang Beautiful cotton, beautiful scenery,...</td>\n",
       "      <td>0.977775</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Leftists' willingness to blindly believe Chine...</td>\n",
       "      <td>0.967885</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  probability  is_ccp\n",
       "1   We pledge: No more tears on our land\\nIn wrath...     0.999959     0.0\n",
       "2   Get Lost in a #Snow-Blanketed #Wonderland this...     0.999473     0.0\n",
       "3   @VOAChinese The cotton produced in #Xinjiang i...     0.999389     0.0\n",
       "4   @CNBC Liars and terrorism supporters, shame on...     0.999000     0.0\n",
       "5   Men's Curling World Championship: #Scotland be...     0.998810     0.0\n",
       "6   @hoopstingley @Vanilla3087 @TrueNorthCentre @T...     0.998790     0.0\n",
       "7   @lukedepulford @RazvenHK Hong Kong is vibrant,...     0.998419     0.0\n",
       "8   A look at Langzhong ancient city in Nanchong, ...     0.997336     0.0\n",
       "9   It should be noted that Hong Kong is facing mu...     0.996620     0.0\n",
       "10  #CyberAttack on Inter Parliamentary Alliance o...     0.995130     0.0\n",
       "11  China's Tianwen-1 spacecraft captures stunning...     0.994811     0.0\n",
       "12  @Flufferbot2 @redsteeze Why not follow #Disney...     0.994390     0.0\n",
       "13  Youtuber : a group of young people from across...     0.994191     0.0\n",
       "14  Challenges of fighting terrorism in Xinjiang -...     0.993676     0.0\n",
       "15  Mr. Wenguis latest short video: Brothers and ...     0.990723     0.0\n",
       "16  #India and #China need to strengthen confidenc...     0.988538     0.0\n",
       "17  @ejXyYC69uapCC7q Don't let Guo Wengui influenc...     0.983925     0.0\n",
       "18  @btslabs_china @ICOboosterteam @ICO_Analytics ...     0.979023     0.0\n",
       "19  #Xinjiang Beautiful cotton, beautiful scenery,...     0.977775     0.0\n",
       "20  Leftists' willingness to blindly believe Chine...     0.967885     0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5a02e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives.to_csv(dataset + '_china_false_positives.csv')\n",
    "false_negatives.to_csv(dataset + '_china_false_negatives.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31cf65",
   "metadata": {},
   "source": [
    "## What was the model least certain about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d7159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([i for [i] in model.predict(X_test)])\n",
    "y_pred_uncertain = np.abs(y_pred - 0.5)\n",
    "y_uncertain_argsort = np.argsort(y_pred_uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19175aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = 20\n",
    "\n",
    "uncertains = pd.DataFrame(columns=['text', 'probability', 'is_ccp'])\n",
    "\n",
    "for i in range(num_results):\n",
    "    details = pd.DataFrame({'text': test.iloc[y_uncertain_argsort[i]].text, 'probability': y_pred[y_uncertain_argsort[i]], 'is_ccp': test.iloc[y_uncertain_argsort[i]].is_ccp}, index=[i + 1])\n",
    "    uncertains = pd.concat([uncertains, details])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e71bef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertains.to_csv(dataset + '_china_least_certains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "775b7d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>probability</th>\n",
       "      <th>is_ccp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 killed, 19 injured in China truck-bus highw...</td>\n",
       "      <td>0.506093</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#ChinaToday in case you missed it: - Xi stress...</td>\n",
       "      <td>0.510257</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ChinaToday in case you missed it:\\n- Highligh...</td>\n",
       "      <td>0.510384</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kerry: US 'hopeful' it can work with China to ...</td>\n",
       "      <td>0.512026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@oU1QSfoQi1MfaF5 Guo Wengui has everything for...</td>\n",
       "      <td>0.512959</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I wonder what would the world say if this happ...</td>\n",
       "      <td>0.487033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When China grounded its Boeing 737 MAX planes ...</td>\n",
       "      <td>0.514770</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@JianluBi Xinjiang people dance whenever they ...</td>\n",
       "      <td>0.484868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Speaking of # friends, that's really a nove...</td>\n",
       "      <td>0.482069</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Minibus driver dies in car explosion in NW Chi...</td>\n",
       "      <td>0.476607</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>China's central bank has proposed global stand...</td>\n",
       "      <td>0.467611</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Stories of CPC\" Thematic Briefing on Xinjiang...</td>\n",
       "      <td>0.536118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@Macker202 @guardian Von Trapped in Xinjiang</td>\n",
       "      <td>0.462925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @PandemicTruther: Far reaching significance...</td>\n",
       "      <td>0.537216</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@Angelo4justice3 Check out my Tweets on real #...</td>\n",
       "      <td>0.537870</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tours tailored around Xinjiang culture boost v...</td>\n",
       "      <td>0.461793</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#XiJinping extends condolences over death of S...</td>\n",
       "      <td>0.538963</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@AuroraBlogspot @Gem353 1/2 Kenneth Rapoza on ...</td>\n",
       "      <td>0.460519</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @CyPhyCon: Don't be too shocked, but it loo...</td>\n",
       "      <td>0.542550</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#COVID19  The Governor of New York urged the U...</td>\n",
       "      <td>0.542624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  probability  is_ccp\n",
       "1   11 killed, 19 injured in China truck-bus highw...     0.506093     0.0\n",
       "2   #ChinaToday in case you missed it: - Xi stress...     0.510257     1.0\n",
       "3   #ChinaToday in case you missed it:\\n- Highligh...     0.510384     1.0\n",
       "4   Kerry: US 'hopeful' it can work with China to ...     0.512026     0.0\n",
       "5   @oU1QSfoQi1MfaF5 Guo Wengui has everything for...     0.512959     0.0\n",
       "6   I wonder what would the world say if this happ...     0.487033     1.0\n",
       "7   When China grounded its Boeing 737 MAX planes ...     0.514770     1.0\n",
       "8   @JianluBi Xinjiang people dance whenever they ...     0.484868     1.0\n",
       "9   Speaking of # friends, that's really a nove...     0.482069     1.0\n",
       "10  Minibus driver dies in car explosion in NW Chi...     0.476607     1.0\n",
       "11  China's central bank has proposed global stand...     0.467611     0.0\n",
       "12  \"Stories of CPC\" Thematic Briefing on Xinjiang...     0.536118     1.0\n",
       "13       @Macker202 @guardian Von Trapped in Xinjiang     0.462925     0.0\n",
       "14  RT @PandemicTruther: Far reaching significance...     0.537216     1.0\n",
       "15  @Angelo4justice3 Check out my Tweets on real #...     0.537870     0.0\n",
       "16  Tours tailored around Xinjiang culture boost v...     0.461793     1.0\n",
       "17  #XiJinping extends condolences over death of S...     0.538963     1.0\n",
       "18  @AuroraBlogspot @Gem353 1/2 Kenneth Rapoza on ...     0.460519     0.0\n",
       "19  RT @CyPhyCon: Don't be too shocked, but it loo...     0.542550     1.0\n",
       "20  #COVID19  The Governor of New York urged the U...     0.542624     1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee04cfa",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier for Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb152a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacobbarkow/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b9882a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clf_pred = clf.predict(X_test)\n",
    "y_clf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76264ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9480    0.9284    0.9381      3908\n",
      "         1.0     0.9286    0.9482    0.9383      3839\n",
      "\n",
      "    accuracy                         0.9382      7747\n",
      "   macro avg     0.9383    0.9383    0.9382      7747\n",
      "weighted avg     0.9384    0.9382    0.9382      7747\n",
      "\n",
      "[[3628  280]\n",
      " [ 199 3640]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_clf_pred,  digits=4))\n",
    "print(confusion_matrix(y_test, y_clf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084dc8fe",
   "metadata": {},
   "source": [
    "## Testing on other set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe643fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_other = 'all' if dataset == 'pro' else 'pro'\n",
    "\n",
    "tweets_other = pd.read_csv('../bertweet_embeddings/' + dataset_other + '_china_full_nort.csv')\n",
    "tweets_other = tweets_other.dropna() # some rows come in as blank so they need to be dropped\n",
    "xxx, test_other = train_test_split(tweets_other, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e11d9288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38734, 768]) (38734, 3)\n"
     ]
    }
   ],
   "source": [
    "embeddings_other = torch.Tensor()\n",
    "\n",
    "for i in range(39):\n",
    "    filename = \"../bertweet_embeddings/embeddings/\" + dataset_other + \"_china_embedding_\" + str(i*1000) + \".pt\"\n",
    "    embeddings_other = torch.cat((embeddings_other, torch.load(filename)))\n",
    "    \n",
    "print(embeddings_other.shape, tweets_other.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "676d4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8896  830]\n",
      " [ 203 9438]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.977690</td>\n",
       "      <td>0.914662</td>\n",
       "      <td>0.945126</td>\n",
       "      <td>9726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.919166</td>\n",
       "      <td>0.978944</td>\n",
       "      <td>0.948114</td>\n",
       "      <td>9641.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.946662</td>\n",
       "      <td>0.946662</td>\n",
       "      <td>0.946662</td>\n",
       "      <td>0.946662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.948428</td>\n",
       "      <td>0.946803</td>\n",
       "      <td>0.946620</td>\n",
       "      <td>19367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.948557</td>\n",
       "      <td>0.946662</td>\n",
       "      <td>0.946613</td>\n",
       "      <td>19367.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0.0            0.977690  0.914662  0.945126   9726.000000\n",
       "1.0            0.919166  0.978944  0.948114   9641.000000\n",
       "accuracy       0.946662  0.946662  0.946662      0.946662\n",
       "macro avg      0.948428  0.946803  0.946620  19367.000000\n",
       "weighted avg   0.948557  0.946662  0.946613  19367.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_other = embeddings_other[test_other.index].detach().numpy()\n",
    "y_test_other = test_other['is_ccp']\n",
    "\n",
    "y_pred_other = model.predict(X_test_other)\n",
    "y_pred_other_bool = np.where(y_pred_other >= 0.5, 1, 0).ravel() #DIY function to round outputs to 0 or 1\n",
    "\n",
    "report = classification_report(y_test_other, y_pred_other_bool, output_dict=True, digits=4)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(confusion_matrix(y_test_other, y_pred_other_bool,))\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
