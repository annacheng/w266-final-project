{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2491f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b084ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "# For transformers v4.x+: \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52ec6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../bertweet_embeddings/pro_china_full_nort.csv')\n",
    "tweets = tweets.dropna().reset_index() # some rows come in as blank so they need to be dropped - also need to reset index so they can match embeddings later\n",
    "\n",
    "train, test = train_test_split(tweets, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3075ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell tests for invalid or blank text entries and prints their index if one comes up\n",
    "\n",
    "# for idx, tweet in enumerate(tweets['text']):\n",
    "#     try: \n",
    "#         tokenizer(tweet, padding='max_length', max_length=130, return_tensors=\"pt\")\n",
    "#     except:\n",
    "#         print(idx, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c600cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38734, 768]) (38734, 4)\n"
     ]
    }
   ],
   "source": [
    "# reading in tensors from file\n",
    "\n",
    "embeddings = torch.Tensor()\n",
    "\n",
    "for i in range(39):\n",
    "    filename = \"../bertweet_embeddings/embeddings/pro_china_embedding_\" + str(i*1000) + \".pt\"\n",
    "    embeddings = torch.cat((embeddings, torch.load(filename)))\n",
    "    \n",
    "print(embeddings.shape, tweets.shape) # these should be in agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddd709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30987, 768) (30987,)\n"
     ]
    }
   ],
   "source": [
    "X_train = embeddings[train.index].detach().numpy()\n",
    "y_train = train['is_ccp']\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394341d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "\n",
    "# model.add(keras.layers.Dense(512, \n",
    "#                              activation = 'relu',\n",
    "#                              kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "#                              bias_regularizer=keras.regularizers.l2(1e-4),\n",
    "#                              activity_regularizer=keras.regularizers.l2(1e-5)))\n",
    "# model.add(keras.layers.Dropout(0.1))\n",
    "# model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# # adam optimizer is a fancier version of gradient descent.  You can read more about it here: https://arxiv.org/pdf/1412.6980.pdf\n",
    "# optimizer = keras.optimizers.Adam(clipvalue=1)\n",
    "\n",
    "# model.compile(optimizer=optimizer,\n",
    "#               loss='binary_crossentropy',  # From information theory notebooks.\n",
    "#               metrics=['accuracy'])        # What metric to output as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e3743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "#model.add(keras.layers.Normalization())\n",
    "\n",
    "model.add(keras.layers.Dense(16, \n",
    "                             activation = 'relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#optimizer = keras.optimizers.Adam(clipvalue=1, learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5aa13db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "969/969 [==============================] - 2s 1ms/step - loss: 0.2978 - accuracy: 0.8823\n",
      "Epoch 2/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.2070 - accuracy: 0.9165\n",
      "Epoch 3/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1865 - accuracy: 0.9257\n",
      "Epoch 4/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1768 - accuracy: 0.9314\n",
      "Epoch 5/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1699 - accuracy: 0.9342\n",
      "Epoch 6/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1656 - accuracy: 0.9353\n",
      "Epoch 7/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9369\n",
      "Epoch 8/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1587 - accuracy: 0.9381\n",
      "Epoch 9/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1562 - accuracy: 0.9395\n",
      "Epoch 10/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1525 - accuracy: 0.9415\n",
      "Epoch 11/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1494 - accuracy: 0.9422\n",
      "Epoch 12/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1472 - accuracy: 0.9437\n",
      "Epoch 13/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9438\n",
      "Epoch 14/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1418 - accuracy: 0.9456\n",
      "Epoch 15/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1396 - accuracy: 0.9460\n",
      "Epoch 16/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1382 - accuracy: 0.9461\n",
      "Epoch 17/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1371 - accuracy: 0.9470\n",
      "Epoch 18/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1355 - accuracy: 0.9481\n",
      "Epoch 19/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1345 - accuracy: 0.9484\n",
      "Epoch 20/20\n",
      "969/969 [==============================] - 1s 1ms/step - loss: 0.1314 - accuracy: 0.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e47789340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df861659",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1808b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = embeddings[test.index].detach().numpy()\n",
    "y_test = test['is_ccp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b28473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95      3857\n",
      "         1.0       0.94      0.95      0.95      3890\n",
      "\n",
      "    accuracy                           0.95      7747\n",
      "   macro avg       0.95      0.95      0.95      7747\n",
      "weighted avg       0.95      0.95      0.95      7747\n",
      "\n",
      "[[3639  218]\n",
      " [ 201 3689]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_bool = np.where(y_pred >= 0.5, 1, 0).ravel() #DIY function to round outputs to 0 or 1\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))\n",
    "print(confusion_matrix(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3516747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 882us/step - loss: 0.1397 - accuracy: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13970305025577545, 0.9459145665168762]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc962bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8776716]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one line tester\n",
    "\n",
    "line = \"xinjiang is a slavery concentration camp\"\n",
    "line_token = tokenizer(line, padding='max_length', max_length=130, return_tensors=\"pt\")\n",
    "line_embed = bertweet(**line_token)\n",
    "\n",
    "model.predict(line_embed.pooler_output.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dcf22d",
   "metadata": {},
   "source": [
    "# Test on All China set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86789eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_all = pd.read_csv('../bertweet_embeddings/all_china_full_nort.csv')\n",
    "tweets_all = tweets_all.dropna() # some rows come in as blank so they need to be dropped\n",
    "xxx, test_all = train_test_split(tweets_all, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ca2a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38733, 768]) (38734, 4)\n"
     ]
    }
   ],
   "source": [
    "embeddings_all = torch.Tensor()\n",
    "\n",
    "for i in range(39):\n",
    "    filename = \"../bertweet_embeddings/embeddings/all_china_embedding_\" + str(i*1000) + \".pt\"\n",
    "    embeddings_all = torch.cat((embeddings_all, torch.load(filename)))\n",
    "    \n",
    "print(embeddings_all.shape, tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab5a93e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.76      0.84      9726\n",
      "         1.0       0.80      0.95      0.87      9641\n",
      "\n",
      "    accuracy                           0.86     19367\n",
      "   macro avg       0.87      0.86      0.85     19367\n",
      "weighted avg       0.87      0.86      0.85     19367\n",
      "\n",
      "[[7405 2321]\n",
      " [ 484 9157]]\n",
      "606/606 [==============================] - 1s 1ms/step - loss: 0.3975 - accuracy: 0.8552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39753246307373047, 0.8551660180091858]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_all = embeddings_all[test_all.index].detach().numpy()\n",
    "y_test_all = test_all['is_ccp']\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_all = model.predict(X_test_all)\n",
    "y_pred_all_bool = np.where(y_pred_all >= 0.5, 1, 0).ravel() #DIY function to round outputs to 0 or 1\n",
    "\n",
    "print(classification_report(y_test_all, y_pred_all_bool))\n",
    "print(confusion_matrix(y_test_all, y_pred_all_bool))\n",
    "\n",
    "model.evaluate(X_test_all, y_test_all)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
